---
title: Ceph社区动态（2022-4-16~2022-5-31）
category: blog 
date: 2022-6-27
tags:
    - Ceph
    - 动态
    - Pacific
    - openEuler
sig: ceph-sig
archives: 2022-6
author: rosinL
summary: Ceph社区动态
---
# Ceph社区动态（2022-4-16~2022-5-31）
## [Ceph v16.2.8/9 Pacific released](https://ceph.io/en/news/blog/2022/v16-2-8-pacific-released/)
16.2.8版本主要涉及特性更新及bug修复，16.2.9是一个火速补丁版本。
相比于16.2.7版本，有如下主要更新：
* MON/MGR
  - 创建存储池，可以指定`--bluk`标志。指定了`--bluk`的存储池可以在创建之初使能`pg_autoscaler`特性，以获得更好的性能；未指定`--bulk`的存储池则不会启用`pg_autoscaler`特性。[特性链接](https://docs.ceph.com/en/latest/rados/operations/placement-groups/)。
* MGR
  - `pg_autoscaler`功能可以使用`noautoscale`标志全局使能或关闭。默认`noautoscale`标志未置位，`pg_autoscaler`状态与上一版本保持一致。
* Ceph集群状态
  - 集群升级后，如果`require-osd-release`标志未设置为恰当的版本，会报`health warning`。
* CephFS
  - 多MDS场景，升级元数据服务时，需确保除rank0外，无过期文件或目录挂在活动rank下。[特性链接](https://docs.ceph.com/en/latest/releases/pacific/#upgrading-from-octopus-or-nautilus)

## 近期社区合入pr
近期pr主要以bug修复为主，摘选了部分如下：
* BlueStore:
  - RocksDB iterator Bounding优化合入，避免频繁的omap全局迭代 [pr#45904](https://github.com/ceph/ceph/pull/45904)
  - AVL查找优化，有助于提升NVMe盘带宽 [pr#45884](https://github.com/ceph/ceph/pull/45884)
  - 在Bluestore中实现了CoDel算法，缓解后端存储的缓存膨胀问题 [pr#43413](https://github.com/ceph/ceph/pull/43413)
* mgr：
  - 将perf counter相关功能打包成一个exporter，降低mgr开销 [pr#45220](https://github.com/ceph/ceph/pull/45220)
  - 增加元数据操作的命令，`ceph fs subvolume metadata get/set/list/remove` [pr#45603](https://github.com/ceph/ceph/pull/45603)
  - 使用mgr handle_mon_map提供mon元数据更新的能力 [pr#45670](https://github.com/ceph/ceph/pull/45670)
  - 每个fsid对应一个ceph.conf文件供cephadmin内部使用，不再依赖固定的`/etc/ceph`，存放路径：`/var/lib/ceph/<fsid>/config`[pr#45877](https://github.com/ceph/ceph/pull/45877)
* rgw：
  - sse-s3特性增强，基于亚马逊sse标准，使用`vault`管理密钥，put/get IO路径支持实现桶级别的加密[pr#44494](https://github.com/ceph/ceph/pull/44494)
  - rgw zipper项目包括两部分，一部分是api抽象层，兼容s3，swift IO访问；另一部分是后端存储dbstore，兼容不同的存储平台（rados，sql数据库等）[pr#45623](https://github.com/ceph/ceph/pull/45623)
  - D3N和arrow特性增强[pr#46080](https://github.com/ceph/ceph/pull/46080)
* 其他：
  - rbd和rgw的bug修复
  - 文档修复

## 近期Ceph Developer动态
Ceph社区各个模块会定期举行会议，讨论和对齐开发进展，会后有视频上传至[youtube](https://www.youtube.com/channel/UCno-Fry25FJ7B4RycCxOtfw/videos)，主要会议信息如下：
|会议名称|说明|频率|
|-------|----|----|
|Crimson SeaStore OSD Weekly Meeting |Crimson & Seastore开发周例会|周|
|Ceph Orchestration Meeting|Ceph管理模块（Mgr）开发|周|
|Ceph DocUBetter Meeting |文档优化|双周|
|Ceph Performance Meeting|Ceph性能优化|双周|
|Ceph Developer Monthly|Ceph开发者月度例会|月|
|Ceph Testing Meeting|版本验证及发布例会|月|
|Ceph Science User Group Meeting|Ceph科学计算领域会议|不定期|
|Ceph Leadership Team Meeting|Ceph领导团队例会|周|
|Ceph Tech talks|Ceph社区技术相关主题讨论|月|

### Performance Meeting
* Crimson社区测试进展
  - Crimson + tcmalloc: 内存管理功能正常，社区正在开发中，目前存在一些aborts&segfaults异常
  - Crimson + libc malloc: 存在单osd内存使用过高的问题，测试数据达到23~33GB/osd
  - Crimson + bluestore: 无论是tcmalloc，还是libc malloc，写IO过程会出现阻塞重连问题。
* [RocksDB iterator Bounding](https://github.com/ceph/ceph/pull/45904)优化总结
  - 优化特性已经合入，并回合至Pacific版本16.2.8中。
* Bluestore WAL特性
  - 特性代码：详见[ifed01](https://github.com/ifed01/ceph)仓的wip-ifed-bluewal分支
  - 具社区初步验证，4K随机写场景最高会有50%的性能提升。该特性目前主要有pglog更新、内存增长的一些问题，暂无重大bug，进一步跟踪。
